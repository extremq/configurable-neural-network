{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "import scipy.misc as misc\n",
    "import warnings\n",
    "import torch as th\n",
    "%matplotlib inline\n",
    "\n",
    "dtype = th.float\n",
    "\n",
    "# Uncomment for device type\n",
    "device = th.device(\"cuda:0\")\n",
    "# device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files\n",
    "with open(\"mnist_dataset/mnist_test.csv\", 'r') as test_file:\n",
    "    test_list = test_file.readlines()\n",
    "\n",
    "with open(\"mnist_dataset/mnist_train.csv\", 'r') as train_file:\n",
    "    train_list = train_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing.\n",
    "def softmax(x):\n",
    "    e_x = th.exp(x - th.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def test(network, supress_outputs=True):\n",
    "    verification = list()\n",
    "\n",
    "    for record in test_list:\n",
    "        record = record.split(',')\n",
    "\n",
    "        # Get the label\n",
    "        correct_label = int(record[0])\n",
    "\n",
    "        # Scale it for input\n",
    "        scaled_input = np.asfarray(record[1:]) / 255.0 * 0.99 + 0.01\n",
    "\n",
    "        # Get the result\n",
    "        result = network.query(scaled_input).cpu()\n",
    "\n",
    "        # Apply SoftMax\n",
    "        result = softmax(result)\n",
    "\n",
    "        # Get the predicted label\n",
    "        predicted_label = np.argmax(result)\n",
    "\n",
    "        if predicted_label == correct_label:\n",
    "            verification.append(1)\n",
    "        else:\n",
    "            verification.append(0)\n",
    "\n",
    "    if not supress_outputs:\n",
    "        print(f\"Out of {len(verification)} images, the network correctly predicted {sum(verification)}\")\n",
    "        print(\n",
    "            f\"Accuracy is {np.round(sum(verification) / len(verification) * 100, 2)}%\")\n",
    "    \n",
    "    return sum(verification) / len(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, dimensions, learning_rate: float, activation_function: str = \"relu\"):\n",
    "        if len(dimensions) < 2:\n",
    "            raise TypeError(\n",
    "                \"dimensions argument needs to have at least two elements\")\n",
    "\n",
    "        # Set object properties\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dimensions = dimensions\n",
    "\n",
    "        self.init_layers()\n",
    "\n",
    "        # Activation function selector\n",
    "        match activation_function.lower():\n",
    "            case \"sigmoid\":\n",
    "                self.method = \"sigmoid\"\n",
    "                self.activation_function = th.nn.Sigmoid()\n",
    "                self.init_weights()\n",
    "            case \"relu\":\n",
    "                self.method = \"relu\"\n",
    "                self.activation_function = th.nn.ReLU()\n",
    "                self.init_weights()\n",
    "            case _:\n",
    "                self.method = \"relu\"\n",
    "                self.activation_function = th.nn.ReLU()\n",
    "                self.init_weights()\n",
    "\n",
    "                warnings.warn(\n",
    "                    f\"'{activation_function}' is not a valid parameter for activation function, defaulting to ReLU.\")\n",
    "\n",
    "    # Builds the necessary numpy vectors for representing the layer nodes\n",
    "    def init_layers(self):\n",
    "        self.layers = list()\n",
    "\n",
    "        for index in range(len(self.dimensions)):\n",
    "            # Vectors of node_count rows\n",
    "            self.layers.append(th.empty(size=(self.dimensions[index], 1), device=device, dtype=dtype))\n",
    "\n",
    "    # Builds the necessary numpy matrices for representing the weights\n",
    "    def init_weights(self):\n",
    "        self.weights = list()\n",
    "\n",
    "        for index in range(len(self.dimensions) - 1):\n",
    "            # Matrices must have the next layer's node count as rows and the current layer's node count as columns\n",
    "            # For example, the first layer after input will receive\n",
    "            # WeightMatrix * InputVector and it must result into a vector of the next layer's rows.\n",
    "            current_layer_node_count = self.dimensions[index]\n",
    "            next_layer_node_count = self.dimensions[index + 1]\n",
    "\n",
    "            match self.method:\n",
    "                case \"relu\":\n",
    "                    # Using Glorot Normal Initialization\n",
    "                    # (https://stats.stackexchange.com/questions/339054/what-values-should-initial-weights-for-a-relu-network-be)\n",
    "                    # standard_deviation = sqrt(2 / (fan_in + fan_out))\n",
    "                    standard_deviation = th.sqrt(\n",
    "                        2 / (current_layer_node_count + next_layer_node_count))\n",
    "                    self.weights.append(\n",
    "                        th.normal(\n",
    "                            mean=0.0,\n",
    "                            std=standard_deviation,\n",
    "                            size=(next_layer_node_count,\n",
    "                                  current_layer_node_count),\n",
    "                            device=device,\n",
    "                            dtype=dtype\n",
    "                        ) + 0.01\n",
    "                    )\n",
    "                case \"sigmoid\":\n",
    "                    self.weights.append(\n",
    "                        th.rand(\n",
    "                            size=(next_layer_node_count,\n",
    "                                  current_layer_node_count),\n",
    "                            device=device,\n",
    "                            dtype=dtype\n",
    "                        ) - 0.5\n",
    "                    )\n",
    "\n",
    "    # Trains the neural network using backpropagation\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        targets = th.from_numpy(np.array(targets_list, ndmin=2).T).float().to(device)\n",
    "\n",
    "        # Let's run the input through\n",
    "        self.query(inputs_list)\n",
    "\n",
    "        # Computing the cost function\n",
    "        # error = (target - final_output)\n",
    "        error_vector = (targets - self.layers[len(self.dimensions) - 1])\n",
    "\n",
    "        # Update the weights\n",
    "        for index in range(len(self.dimensions) - 2, -1, -1):\n",
    "            # Choose partial derivative\n",
    "            match self.method:\n",
    "                case \"relu\":\n",
    "                    self.weights[index] += self.learning_rate * th.matmul(\n",
    "                        error_vector * th.heaviside(self.layers[index + 1], 1), self.layers[index].t())\n",
    "                case \"sigmoid\":\n",
    "                    self.weights[index] += self.learning_rate * th.matmul(\n",
    "                        error_vector * self.layers[index + 1] * (1 - self.layers[index + 1]), self.layers[index].t())\n",
    "\n",
    "            # Propagate errors accordingly\n",
    "            if index != 0:\n",
    "                error_vector = th.matmul(self.weights[index].t(), error_vector)\n",
    "\n",
    "    # Queries the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # Convert inputs list to 2d array\n",
    "        self.layers[0] = th.from_numpy(np.array(inputs_list, ndmin=2).T).float().to(device)\n",
    "\n",
    "        # Go through all layers and compute the outputs\n",
    "        for index in range(1, len(self.dimensions)):\n",
    "            self.layers[index] = th.matmul(\n",
    "                self.weights[index - 1], self.layers[index - 1]\n",
    "            )\n",
    "            self.layers[index] = self.activation_function(self.layers[index])\n",
    "\n",
    "        return self.layers[len(self.dimensions) - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the network\n",
    "\n",
    "# 784 pixels for input layer, 2 20-nodes hidden layers and one 10-node output layer\n",
    "dimensions = np.array([28 * 28, 500, 10])\n",
    "learning_rate = 0.12\n",
    "\n",
    "network = NeuralNetwork(dimensions=dimensions,\n",
    "                  activation_function=\"sigmoid\", learning_rate=learning_rate)\n",
    "\n",
    "performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for index, record in enumerate(train_list):\n",
    "        # Transform one of them to an image\n",
    "        record = record.split(',')\n",
    "\n",
    "        # Scale input to [0.01, 1.00]\n",
    "        scaled_input = np.asfarray(record[1:]) / 255.0 * 0.99 + 0.01\n",
    "\n",
    "        # Make output nodes\n",
    "        nodes = 10\n",
    "        targets = np.zeros(10) + 0.01\n",
    "        targets[int(record[0])] = 0.99\n",
    "\n",
    "        # Train.\n",
    "        network.train(inputs_list=scaled_input, targets_list=targets)\n",
    "    \n",
    "    performance.append(test(network=network))\n",
    "    \n",
    "plt.plot(np.arange(len(performance)), performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9577, 0.9675, 0.9722]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb62f3be680cc27bb615586daf6457a9270ff9741d9ec8090b3edffd096e84d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
